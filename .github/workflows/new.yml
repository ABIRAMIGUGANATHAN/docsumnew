name: DocSum End-to-End Automation

on:
  workflow_dispatch:  # Manual trigger, you can add push/pr if needed

jobs:
  deploy-and-test:
    runs-on: ubuntu-latest
    env:
      LLM_MODEL_ID: Intel/neural-chat-7b-v3-3
      host_ip: 127.0.0.1
      HUGGINGFACEHUB_API_TOKEN: ${{ secrets.HUGGINGFACEHUB_API_TOKEN }}

    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3

      - name: Set up Docker
        run: |
          sudo apt-get update
          sudo apt-get install -y docker-compose

      - name: Source Env Variables
        run: |
          source docsumnew/docker_compose/set_env.sh
          echo "Environment set."

      - name: Deploy DocSum with Docker Compose
        run: |
          cd docsumnew/docker_compose/intel/cpu/xeon/
          docker compose -f compose.yaml up -d

      - name: Wait for DocSum service to be ready
        run: |
          for i in {1..30}; do
            if curl -s http://localhost:8888/v1/docsum; then
              echo "Service ready"
              break
            fi
            echo "Waiting for service..."
            sleep 5
          done

      - name: Test Summarization Endpoint
        run: |
          curl -X POST http://localhost:8888/v1/docsum \
            -H "Content-Type: application/json" \
            -d '{"type": "text", "messages": "Text Embeddings Inference (TEI) is a toolkit for deploying and serving open source text embeddings and sequence classification models."}' \
            -o result.json -s -w "\nStatus Code: %{http_code}\n"

          echo "Summary Output:"
          cat result.json

      - name: Tear Down Docker Containers
        if: always()
        run: |
          cd docsumnew/docker_compose/intel/cpu/xeon/
          docker compose -f compose.yaml down
