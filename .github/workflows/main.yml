name: Document Summarization CI/CD

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

jobs:
  setup-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set Environment Variables
        run: |
          echo "MAX_INPUT_TOKENS=1024" >> $GITHUB_ENV
          echo "MAX_TOTAL_TOKENS=2048" >> $GITHUB_ENV
          echo "no_proxy=${{ secrets.NO_PROXY }},${{ secrets.HOST_IP }}" >> $GITHUB_ENV
          echo "MEGA_SERVICE_HOST_IP=${{ secrets.HOST_IP }}" >> $GITHUB_ENV
          echo "LLM_SERVICE_HOST_IP=${{ secrets.HOST_IP }}" >> $GITHUB_ENV
          echo "ASR_SERVICE_HOST_IP=${{ secrets.HOST_IP }}" >> $GITHUB_ENV
          echo "LLM_MODEL_ID=Intel/neural-chat-7b-v3-3" >> $GITHUB_ENV
          echo "BACKEND_SERVICE_ENDPOINT=http://${{ secrets.HOST_IP }}:8888/v1/docsum" >> $GITHUB_ENV
          echo "LLM_ENDPOINT_PORT=8008" >> $GITHUB_ENV
          echo "DOCSUM_PORT=9000" >> $GITHUB_ENV
          echo "LLM_ENDPOINT=http://${{ secrets.HOST_IP }}:8008" >> $GITHUB_ENV
          echo "DocSum_COMPONENT_NAME=OpeaDocSumTgi" >> $GITHUB_ENV
          echo "HOST_IP=${{ secrets.HOST_IP }}" >> $GITHUB_ENV
          echo "NO_PROXY=${{ secrets.NO_PROXY }}" >> $GITHUB_ENV
          echo "HUGGINGFACEHUB_API_TOKEN=${{ secrets.HUGGINGFACEHUB_API_TOKEN }}" >> $GITHUB_ENV

      - name: Deploy Using Docker with Retry
        run: |
          COMPOSE_PATH="docker_compose/intel/cpu/xeon/compose.yaml"
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Attempt #$((RETRY_COUNT+1)) to start the containers"
            
            docker compose -f $COMPOSE_PATH down  # Stop existing containers
            docker compose -f $COMPOSE_PATH up -d
            
            echo "Waiting for containers to stabilize..."
            sleep 30  # Allow time for services to start
            
            # Check if tgi-server is healthy
            if docker ps | grep -q "tgi-server"; then
              echo "tgi-server is running successfully."
              break
            else
              echo "tgi-server failed to start, retrying..."
              ((RETRY_COUNT++))
            fi
          done

          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "tgi-server failed to start after $MAX_RETRIES attempts."
            exit 1
          fi

  test-document-summarization:
    needs: setup-and-deploy
    runs-on: ubuntu-latest
    steps:
      - name: Test Text Summarization (English)
        run: |
          curl -X POST http://${{ env.HOST_IP }}:8888/v1/docsum \
               -H "Content-Type: application/json" \
               -d '{"type": "text", "messages": "Text Embeddings Inference (TEI) is a toolkit for deploying and serving open source text embeddings and sequence classification models. TEI enables high-performance extraction for the most popular models, including FlagEmbedding, Ember, GTE and E5."}'

      - name: Cleanup
        if: always()
        run: |
          cd docker_compose/intel/cpu/xeon/
          docker compose -f compose.yaml down
